{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Práctica 2: Lectura y manipulación de datos con pandas**\n",
    "\n",
    "En esta práctica, se cargan los datos en marcos de datos (inglés: data frame) con la librería pandas\n",
    "\n",
    "https://pandas.pydata.org/\n",
    "\n",
    "para poder iniciar su procesamiento. \n",
    "\n",
    "En el caso de estudio ejemplo de la profesora, las metas de la práctica son\n",
    "\n",
    "1. combinar la información de los resultados de 1ra y 2da oportunidad con los datos de las encuestas\n",
    "2. agregar una variable categórica para cada alumno, nombrando los casos de la siguiente forma\n",
    "    * 1ra: aprobó la unidad de aprendizaje en primera oportunidad\n",
    "    * 2da: aprobó la unidad de aprendizaje en segunda oportunidad\n",
    "    * 3ra: presentó y reprobó ambas la 1ra y la 2da oportunidad\n",
    "    * 5ta: no participó lo suficiente para tener derecho a segunda oportunidad\n",
    "    *  NA: no se cuenta con información sobre sí o no participó o tuvo derecho en 1ra y 2da oportunidad \n",
    "3. extraer datos de encuestas para un caso específico o para una combinación de casos\n",
    "4. determinar cuántos estudiantes por semestre y por maestro hay en cada caso\n",
    "\n",
    "y cada quien propondrá metas de este tipo para su segundo reporte. \n",
    "\n",
    "El primer intento de "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "enc_ini = pd.read_csv(\"ini.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lanza una multitud de errores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\", line 678, in parser_f\n",
    "    return _read(filepath_or_buffer, kwds)\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\", line 446, in _read\n",
    "    data = parser.read(nrows)\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1036, in read\n",
    "    ret = self._engine.read(nrows)\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1848, in read\n",
    "    data = self._reader.read(nrows)\n",
    "  File \"pandas/_libs/parsers.pyx\", line 876, in pandas._libs.parsers.TextReader.read\n",
    "  File \"pandas/_libs/parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._read_low_memory\n",
    "  File \"pandas/_libs/parsers.pyx\", line 945, in pandas._libs.parsers.TextReader._read_rows\n",
    "  File \"pandas/_libs/parsers.pyx\", line 932, in pandas._libs.parsers.TextReader._tokenize_rows\n",
    "  File \"pandas/_libs/parsers.pyx\", line 2112, in pandas._libs.parsers.raise_parser_error\n",
    "pandas.errors.ParserError: Error tokenizing data. C error: Expected 19 fields in line 680, saw 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinta que el número de columnas por renglón es variable. Investigemos. \n",
    "\n",
    "Abriendo el archivo en emacs, lo primero que resalta son los mugres ˆM saltos de línea de Windows, \n",
    "cortesía de Google Drive (por razones misterio). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emacs ini.csv \n",
    "mv ini.csv ini.win\n",
    "mv mc.csv mc.win\n",
    "mv ord.csv  ord.win\n",
    "tr -d '\\015' < ini.win > ini.csv\n",
    "tr -d '\\015' < mc.win > mc.csv\n",
    "tr -d '\\015' < ord.win > ord.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ya quita esa bronca. Ahora, con awk se puede checar lo de cuántos campos hay en cada renglón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk -F \",\" '{print NF}' ini.csv | sort | uniq -c\n",
    " 513 19\n",
    " 149 20\n",
    "  91 21\n",
    "  59 22\n",
    "  24 23\n",
    "  14 24\n",
    "   8 25\n",
    "   9 26\n",
    "   4 27\n",
    "   1 28\n",
    "   2 29\n",
    "   1 30\n",
    "   2 31\n",
    "   1 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inmediatamente da la idea que algo está muy mal ya que deberían ser las mismas preguntas en cada respuesta.\n",
    "Vamos a ver cuáles líneas son las que faltan preguntas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk -F \",\" '{if (NF < 17) {print $0} }' ini.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y salen cosas como ésta:\n",
    "    \n",
    "...NA,\"la hora clase y cuando de plano no le entienda o tenga tarea, en mis horas libres\",juntarme con compañeros resolviendo dudas,70-79,En que alomejor batallo para aprender algunos conceptos basicos ya que nunca he llevado programacion,23,NA,no se,NA...\n",
    "\n",
    "Esto pasa mucho con encuestas: al responder, han introducido commas en sus respuestas de texto,\n",
    "y ahora pandas cambia de columna con cada comma...\n",
    "\n",
    "Esto es rescatable, ya que cada respuesta que contiene commas está entre comillas dobles. \n",
    "El chiste es ahora recorrer todo el archivo y quitar las commas que vienen entre comillas dobles.\n",
    "\n",
    "Usaré python para ilustrar el principio: \n",
    "* se lee el texto caracter por caracter\n",
    "* al ver una comilla doble, se levanta una bandera (variable booleana)\n",
    "* cada comma que viene mientras la bandera está arriba se omite\n",
    "* a ver la siguiente comilla doble, la bandera se baja\n",
    "    \n",
    "(nuevamente no se puede correr en jupyter porque ocupa un archivo para procesar \n",
    " cuyo nombre se debe proporcionar como parámetro de linéa de instrucciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-873b65771236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "def procesa(line):\n",
    "    salida = ''\n",
    "    ignora = False\n",
    "    for c in line:\n",
    "        if c == '\"':\n",
    "            ignora = not ignora\n",
    "            continue\n",
    "        else:\n",
    "            if c == '\\n':\n",
    "                return salida\n",
    "            if not ignora:\n",
    "                salida += c\n",
    "            elif not c == ',':\n",
    "                salida += c\n",
    "    return salida\n",
    "\n",
    "from sys import argv\n",
    "with open(argv[1], 'r') as input:\n",
    "    for line in input:\n",
    "        print(procesa(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv ini.csv ini.raw\n",
    "mv mc.csv mc.raw\n",
    "mv ord.csv ord.raw\n",
    "python3 puntuacion.py ini.raw > ini.csv\n",
    "python3 puntuacion.py mc.raw > mc.csv\n",
    "python3 puntuacion.py ord.raw > ord.csv\n",
    "awk -F \",\" '{print NF}' ini.csv | sort | uniq -c\n",
    " 878 19\n",
    "awk -F \",\" '{print NF}' mc.csv | sort | uniq -c\n",
    " 575 21\n",
    "awk -F \",\" '{print NF}' ord.csv | sort | uniq -c\n",
    " 459 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya quedó, regresamos a pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import pandas as pd\n",
    ">>> enc_ini = pd.read_csv(\"ini.csv\")\n",
    ">>> enc_mcu = pd.read_csv(\"mc.csv\")\n",
    ">>> enc_ord = pd.read_csv(\"ord.csv\")\n",
    ">>> enc_ini.size\n",
    "16663\n",
    ">>> enc_mcu.size\n",
    "12054\n",
    ">>> enc_ord.size\n",
    "10076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK... ¿Dieciseismil qué es lo que tengo? Según el awk arriba, fueron 878 líneas y 19 columnas en la primera encuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16682\n",
      "16663\n"
     ]
    }
   ],
   "source": [
    "print(878 * 19)\n",
    "print(877 * 19) # finalmente una celda que sí pueden correr en jupyter..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo número coincide, por lo cual podemos concluir que pandas supo usar el primer renglón como una cabecera,\n",
    "asignando nombres a los campos. Todo padre, pero qué se hace cuando el primer renglón *no* contiene una cabecera. Averiguemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat elisa/elisa.csv moi/moi.csv > profes.csv\n",
    "\n",
    "head -n 3 profes.csv \n",
    "elisa,ej17,...6151,NP,NA\n",
    "elisa,ej17,...5232,14,NA\n",
    "elisa,ej17,...0180,75,NA\n",
    "\n",
    "tail -n 3 profes.csv \n",
    "moi,ej18,...9511,100,NA\n",
    "moi,ej18,...9547,100,NA\n",
    "moi,ej18,...5244,NP,NA\n",
    "\n",
    "wc -l profes.csv \n",
    "     521 profes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos datos no contienen cabecera, pero sí son CSV de cinco columnas y 521 renglones.\n",
    "Entonces esperamos obtener 2605 celdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> cf = pd.read_csv(\"../profes.csv\", header=None)\n",
    ">>> cf.size\n",
    "2605"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Éxito. ¿Luego qué si no es un CSV sino tiene espacio como separador como le puse en elisa.dat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 5 ../elisa/elisa.dat \n",
    "sem matr mc eo pr pf Hora_1ra T1_1ra T2_1ra T3_1ra T4_1ra T5_1ra Tareas_1ra PFE_1ra CF_1ra Derecho_1ra NPs_1ra Hora_2da T1_2da T2_2da T3_2da T4_2da T5_2da Tareas_2da PI_2da MC_2da Ord_2da PFE_2da CF_2da\n",
    "ej17 ...6151 NA NA NA NA M4 NP NP NP NP NP 0 NP NP NC 8 NA NA NA NA NA NA NA NA NA NA NA NA\n",
    "ej17 ...5232 NA NA NA NA M4 10 4 NP NP NP 14 NP 14 NC 6 NA NA NA NA NA NA NA NA NA NA NA NA\n",
    "ej17 ...0180 6.0 12.5 5.0 1.0 M4 10 10 10 10 10 50 1 75 NA 0 NA NA NA NA NA NA NA NA NA NA NA NA\n",
    "ej17 ...8175 0.0 9.0 NP NP M4 10 6 NP NP NP 16 NP 25 NC 4 NA NA NA NA NA NA NA NA NA NA NA NA\n",
    "\n",
    "wc -l  ../elisa/elisa.dat \n",
    "     424 ../elisa/elisa.dat\n",
    "\n",
    "awk '{print NF}' < ../elisa/elisa.dat | sort | uniq -c\n",
    "  22 28\n",
    " 402 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh, oh... Hay que limpiar ese archivo antes de procesar. 22 renglones faltan una columna.\n",
    " \n",
    "Inspeccionemos los archivos utilizados en P1 para crear elisa.dat en primer lugar, por si acaso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk -F \",\" '{print NF}' < primera.csv | sort | uniq -c\n",
    " 425 13\n",
    "awk -F \",\" '{print NF}' < segunda.csv | sort | uniq -c\n",
    " 102 14\n",
    "awk '{print NF}' < resultados.txt  | sort | uniq -c\n",
    " 359 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esos tres archivos todos contienen cosas coherentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{if (NF < 29) { print $1 } }' < ../elisa/elisa.dat | sort | uniq -c\n",
    "   1 ad17\n",
    "  21 ad18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son los del último semestre más uno más viejo. A ver en emacs qué faltó agregar a esos. \n",
    "Curiosamente el archivo contiene exactamente 22 espacios dobles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 combine.py | grep \"  \" | wc -l \n",
    "      22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente sustituir el doble espacio auyda en que el formato esté consistente, pero no repone el dato faltante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 combine.py | grep \"  \" | sed 's/  / /g' | awk '{print NF}' | uniq -c\n",
    "  22 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor veamos en qué posición falta el dato (usaré awk para ocultar las matrículas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iMac:elisa elisa$ python3 combine.py | grep \"  \" | sed 's/  / FALTA /g' | awk '{$2 = \"...\"; print $0}'\n",
    "ad17 ... 2.0 10.0 NP NP V4 10 10 10 10 10 50 NP 62 FALTA 1 NA NA NA NA NA NA NA NA NA NA NA NA\n",
    "ad18 ... 1.6666666666666665 7.75 7.0 3.1 M4 10 10 10 10 10 50 3.1 64 FALTA 0 M4 10 10 10 10 10 50 7 1.67 7.75 3.1 70\n",
    "ad18 ... 6.0 4.5 NP NP M4 10 10 10 10 10 50 NP 54 FALTA 1 M4 10 10 10 10 10 50 NP 6 4.5 NP 61\n",
    "ad18 ... 6.166666666666666 7.5 5.0 1.1 M4 10 10 10 10 10 50 1.1 65 FALTA 1 M4 10 10 10 10 10 50 5 6.17 7.5 1.1 70\n",
    "ad18 ... 9.0 6.5 4.0 NP M4 10 10 10 10 10 50 NP 60 FALTA 1 M4 10 10 10 10 10 50 4 9 6.5 NP 70\n",
    "ad18 ... 9.75 0.0 7.0 3.8 M4 10 10 10 10 10 50 3.8 64 FALTA 1 M4 10 10 10 10 10 50 7 9.75 0 3.8 71\n",
    "ad18 ... 6.5 11.5 3.0 NP M4 10 10 10 10 10 50 NP 68 FALTA 1 M4 10 10 10 10 10 50 3 6.5 11.5 NP 71\n",
    "ad18 ... 0.75 NP NP NP M4 10 10 10 10 10 50 NP 51 FALTA 2 M4 NP NP NP NP NP NP NP NP NP NP NP\n",
    "ad18 ... 10.0 8.0 5.0 3.8 M4 10 10 10 10 10 50 3.8 63 FALTA 1 M4 10 10 10 10 10 50 5 10 8 3.8 77\n",
    "ad18 ... 9.0 4.0 2.0 1.0 M4 10 10 10 10 10 50 1 58 FALTA 1 M4 10 10 10 10 10 50 2 9 4 1 66\n",
    "ad18 ... 7.666666666666667 6.75 8.0 NP M4 10 10 10 10 10 50 NP 68 FALTA 0 M4 10 10 10 10 10 50 8 7.67 6.75 NP 72\n",
    "ad18 ... 5.0 7.5 9.0 NP V1 10 10 10 10 10 50 NP 62 FALTA 0 V1 10 10 10 10 10 50 9 5 7.5 NP 72\n",
    "ad18 ... 7.666666666666667 5.25 NP 3.9 V1 10 10 10 10 10 50 3.9 67 FALTA 1 V1 NP NP NP NP NP NP NP NP NP NP NP\n",
    "ad18 ... 8.0 7.25 6.0 NP V1 10 10 10 10 10 50 NP 65 FALTA 1 V1 10 10 10 10 10 50 6 8 7.25 NP 71\n",
    "ad18 ... 9.0 7.5 NP NP V1 10 6 10 10 10 46 NP 46 FALTA 1 V1 10 6 10 10 10 46 NP 9 7.5 NP 63\n",
    "ad18 ... 8.0 11.5 5.0 2.1 V1 10 10 10 10 10 50 2.1 62 FALTA 1 V1 10 10 10 10 10 50 5 8 11.5 2.1 77\n",
    "ad18 ... 6.0 10.25 5.0 2.2 V1 10 10 10 10 10 50 2.2 63 FALTA 1 V1 10 10 10 10 10 50 5 6 10.25 2.2 73\n",
    "ad18 ... 0.75 10.5 9.0 NP V4 10 10 10 10 10 50 NP 62 FALTA 0 V4 10 10 10 10 10 50 9 0.75 10.5 NP 70\n",
    "ad18 ... 12.0 10.75 NP 3.5 V4 10 10 10 10 10 50 3.5 69 FALTA 1 V4 10 10 10 10 10 50 NP 12 10.75 3.5 76\n",
    "ad18 ... 9.0 9.5 NP NP V4 10 10 10 10 10 50 NP 68 FALTA 1 V4 10 10 10 10 10 50 NP 9 9.5 NP 69\n",
    "ad18 ... 8.0 8.25 6.0 NP V4 10 10 10 10 10 50 NP 61 FALTA 1 V4 10 10 10 10 10 50 6 8 8.25 NP 72\n",
    "ad18 ... 9.0 6.5 2.0 NP V4 10 10 10 10 10 50 NP 57 FALTA 1 V4 10 10 10 10 10 50 2 9 6.5 NP 68\n",
    "iMac:elisa elisa$ head -n 1 elisa.dat\n",
    "sem matr mc eo pr pf Hora_1ra T1_1ra T2_1ra T3_1ra T4_1ra T5_1ra Tareas_1ra PFE_1ra CF_1ra Derecho_1ra NPs_1ra Hora_2da T1_2da T2_2da T3_2da T4_2da T5_2da Tareas_2da PI_2da MC_2da Ord_2da PFE_2da CF_2da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer es el sí o no tienen derecho a segunda oportunidad que falta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{if (NF == 29) {print $16}}' elisa.dat | sort | uniq -c\n",
    "  91 CD\n",
    "   1 Derecho_1ra\n",
    " 192 NA\n",
    " 118 NC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debería decir CD (con derecho) o NC (no cumple) o NA (no aplica porque pasó en 1ra),\n",
    "pero he olvidado mis propias reglas y no lo puse para ad18.\n",
    "Efectivamente, abriendo primera.csv como hoja de cálculo en Numbers, contiene celdas sin valor.\n",
    "Ordenando la columna en cuestión por su valor, es rápido rellenar lo que faltó.\n",
    "Eran aquellos que sí tenían derecho en segunda oportunidad que tenían la celda vacía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 combine.py > elisa.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y ahora checamos otra vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iMac:elisa elisa$ awk '{print NF}' < ../elisa/elisa.dat | sort | uniq -c\n",
    " 424 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya. Regresemos a pandas, entonces, esperando 423 * 29 = 12267 celdas, \n",
    "ya que sí hay cabecera, pero los separadores son espacios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> elisa = pd.read_csv(\"../elisa/elisa.dat\", sep=\" \")\n",
    ">>> elisa.size\n",
    "12267"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sigue la parte de combinar la información que tenemos por estudiante y semestre y profesor. \n",
    "Es importante recordar que un mismo alumno puede cursar simultáneamente con dos profesores \n",
    "(improbable, pero no imposible) y que un mismo alumno pueda cursar en múltiples semestres con un mismo profe\n",
    "(en el caso que haya reprobado).\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/merging.html explica las formas de unir data frames. \n",
    "\n",
    "Todo va en función de cómo se llaman las columnas.\n",
    "Mejor revisemos eso primero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> ' '.join(enc_ini.columns.values)\n",
    "'sem tiempo grupo matr PE criterios semAnt significado hrsEstudio hrsComentario tecnicas califEsp baseEst prepa ingreso examenIng otrosEstudios mensaje promActual'\n",
    ">>> ' '.join(enc_mcu.columns.values)\n",
    "'sem tiempo grupo matr prom info cambio significado hrsEstudio comentarioHrs creditos corr tecnicas prepMC comoFue opinionMC califEsp baseEst cualTrabajo hrsTrabajo mensaje'\n",
    ">>> ' '.join(enc_ord.columns.values)\n",
    "'sem tiempo grupo matr cambio significado hrsEstudio hrsComentario tecnicas asesorias vecesAsesorias asesoriasComentario prepOrd comoVaya califEsp baseEst temas apoyo comoOrg medios temasGral mensaje'\n",
    ">>> ' '.join(elisa.columns.values)\n",
    "'sem matr mc eo pr pf Hora_1ra T1_1ra T2_1ra T3_1ra T4_1ra T5_1ra Tareas_1ra PFE_1ra CF_1ra Derecho_1ra NPs_1ra Hora_2da T1_2da T2_2da T3_2da T4_2da T5_2da Tareas_2da PI_2da MC_2da Ord_2da PFE_2da CF_2da'\n",
    ">>> cf.columns = ['profe', 'sem', 'matr', '1ra', '2da']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una bronca en lo que queremos lograr es que las encuestas no tienen un campo que indique el profesor, solamente uno que indica el grupo (un mismo alumno *no*, por suerte, puede inscribir más de un grupo con un mismo profe en un mismo semestre). Lo que se ocupa es *agregar* una columna profe en esos tres data frames, usando reglas tipo \"si dice Elisa en el grupo, entonces ponle elisa como profe, pero si dice Moi, ponle moi\" (no vamos a ni intentar comparar con Moisés; caracteres no-ASCII son la fuente de todas las penas). \n",
    "\n",
    "Como por el momento no contamos con resultados de otros profes (en fases futuras puede resultar necesario incluir más), dejemos los demás campos profe como NA/NaN/None o algo así que indica que aún no sabemos o aún no nos importa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ini['profe'] = ['elisa' if 'Elisa' in str(valor) else 'moi' if 'Moi' in str(valor) else 'NA' for valor in enc_ini['grupo']]\n",
    "enc_mcu['profe'] = ['elisa' if 'Elisa' in str(valor) else 'moi' if 'Moi' in str(valor) else 'NA' for valor in enc_mcu['grupo']]\n",
    "enc_ord['profe'] = ['elisa' if 'Elisa' in str(valor) else 'moi' if 'Moi' in str(valor) else 'NA' for valor in enc_ord['grupo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí podemos combinar esas tres tablas de encuestas con las calificaciones finales del data frame cf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> tmp = pd.merge(enc_ini, enc_mcu, how='outer', on=['profe', 'sem', 'matr'])\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/reshape/merge.py\", line 61, in merge\n",
    "    validate=validate)\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/reshape/merge.py\", line 555, in __init__\n",
    "    self._maybe_coerce_merge_keys()\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/reshape/merge.py\", line 986, in _maybe_coerce_merge_keys\n",
    "    raise ValueError(msg)\n",
    "ValueError: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mmmmkay..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> enc_ini.dtypes\n",
    "sem              object\n",
    "tiempo           object\n",
    "grupo            object\n",
    "matr             object\n",
    "PE               object\n",
    "criterios        object\n",
    "semAnt           object\n",
    "significado      object\n",
    "hrsEstudio       object\n",
    "hrsComentario    object\n",
    "tecnicas         object\n",
    "califEsp         object\n",
    "baseEst          object\n",
    "prepa            object\n",
    "ingreso          object\n",
    "examenIng        object\n",
    "otrosEstudios    object\n",
    "mensaje          object\n",
    "promActual       object\n",
    "profe            object\n",
    "dtype: object\n",
    ">>> enc_mcu.dtypes\n",
    "sem              object\n",
    "tiempo           object\n",
    "grupo            object\n",
    "matr              int64\n",
    "prom             object\n",
    "info             object\n",
    "cambio           object\n",
    "significado      object\n",
    "hrsEstudio       object\n",
    "comentarioHrs    object\n",
    "creditos         object\n",
    "corr             object\n",
    "tecnicas         object\n",
    "prepMC           object\n",
    "comoFue          object\n",
    "opinionMC        object\n",
    "califEsp         object\n",
    "baseEst          object\n",
    "cualTrabajo      object\n",
    "hrsTrabajo       object\n",
    "mensaje          object\n",
    "profe            object\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta madre tiene razón. \n",
    "Por motivos misterio, en la segunda encuesta, las matrículas fueron interpretadas como enteros,\n",
    "mientras en la primera encuesta, fueron strings (objetos). \n",
    "\n",
    "Suele pasar. Los obliguemos a strings, entonces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> enc_mcu['matr'] = [str(valor) for valor in enc_mcu['matr']]\n",
    ">>> enc_mcu.dtypes\n",
    "sem              object\n",
    "tiempo           object\n",
    "grupo            object\n",
    "matr             object\n",
    "prom             object\n",
    "info             object\n",
    "cambio           object\n",
    "significado      object\n",
    "hrsEstudio       object\n",
    "comentarioHrs    object\n",
    "creditos         object\n",
    "corr             object\n",
    "tecnicas         object\n",
    "prepMC           object\n",
    "comoFue          object\n",
    "opinionMC        object\n",
    "califEsp         object\n",
    "baseEst          object\n",
    "cualTrabajo      object\n",
    "hrsTrabajo       object\n",
    "mensaje          object\n",
    "profe            object\n",
    "dtype: object\n",
    ">>> tmp = pd.merge(enc_ini, enc_mcu, how='outer', on=['profe', 'sem', 'matr'])\n",
    ">>> tmp2 = pd.merge(tmp, enc_ord, how='outer', on=['profe', 'sem', 'matr'])\n",
    ">>> datos = pd.merge(tmp2, cf, how='outer', on=['profe', 'sem', 'matr'])\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/reshape/merge.py\", line 61, in merge\n",
    "    validate=validate)\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/reshape/merge.py\", line 555, in __init__\n",
    "    self._maybe_coerce_merge_keys()\n",
    "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/reshape/merge.py\", line 986, in _maybe_coerce_merge_keys\n",
    "    raise ValueError(msg)\n",
    "ValueError: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat\n",
    ">>> cf.dtypes\n",
    "profe    object\n",
    "sem      object\n",
    "matr      int64\n",
    "1ra      object\n",
    "2da      object\n",
    "dtype: object\n",
    ">>> cf['matr'] = [str(valor) for valor in cf['matr']]\n",
    ">>> datos = pd.merge(tmp2, cf, how='outer', on=['profe', 'sem', 'matr'])\n",
    ">>> datos.to_csv('datos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno, ahora supuestamente está todo juntos en un nuevo archivo CSV. \n",
    "Aprovechemos la oportunidad para deshacernos de espacios blancos múltiple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grep '  ' datos.csv | wc -l \n",
    "     113\n",
    "sed 's/  / /g' datos.csv > tmp\n",
    "grep '  ' tmp | wc -l \n",
    "      10\n",
    "sed 's/  / /g' tmp > tmp2\n",
    "grep '  ' tmp2 | wc -l \n",
    "       0\n",
    "mv tmp2 datos.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresemos al awk, sort y uniq para validar que todo esté como se quería y responder las preguntas planteadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l datos.csv \n",
    "    1023 datos.csv\n",
    "awk -F \",\" '{print NF}' < datos.csv | sort | uniq -c\n",
    "1023 62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. Vamos a ver si quedó bien la columna indicando profesor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 1 datos.csv | tr ',' '\\012' | awk '{print NR\": \"$0}' | grep profe\n",
    "21: profe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo puso en la columna 21. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk -F \",\" '{print $21}' datos.csv | sort | uniq -c\n",
    " 443 NA\n",
    " 466 elisa\n",
    " 113 moi\n",
    "   1 profe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son 466 registros de elisa, 113 de moi, una es la cabecera y \n",
    "hay 443 de profes que aún no se han identificado en el data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 1 datos.csv | tr ',' '\\012' | awk '{print NR\": \"$0}' | grep grupo\n",
    "4: grupo_x\n",
    "23: grupo_y\n",
    "42: grupo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparemos con los grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk -F \",\" '{print $21\":\\t\"$4\"\\t\"$23\"\\t\"$42}' tmp | sort | uniq -c\n",
    "   2 NA:\t\t\t\n",
    "   1 NA:\t\t\tBlanca M6\n",
    "   1 NA:\t\t\tSara\n",
    "   1 NA:\t\t\tSara Jueves\n",
    "   8 NA:\t\t\tSara Martes\n",
    "   2 NA:\t\tBlanca M2\tBlanca M2\n",
    "   1 NA:\t\tBlanca M3\tBlanca M3\n",
    "   1 NA:\t\tBlanca M4\tBlanca M4\n",
    "   2 NA:\t\tBlanca M4 2102\t\n",
    "   1 NA:\t\tBlanca M5\tBlanca M5\n",
    "   1 NA:\t\tBlanca M5 2102\t\n",
    "   1 NA:\t\tBlanca M6\t\n",
    "   3 NA:\t\tBlanca M6\tBlanca M6\n",
    "   2 NA:\t\tBlanca M6 2104\t\n",
    "   4 NA:\t\tSara Jueves\t\n",
    "   1 NA:\t\tSara Jueves\tSara\n",
    "   2 NA:\t\tSara Jueves\tSara Jueves\n",
    "   2 NA:\t\tSara Jueves\tSara Martes\n",
    "   3 NA:\t\tSara Martes\t\n",
    "   1 NA:\tAldaco\t\t\n",
    "  15 NA:\tAldaco 7116\t\t\n",
    "   1 NA:\tAldaco 9201\t\t\n",
    "   2 NA:\tAldaco M1 1104\t\t\n",
    "  24 NA:\tAldaco M2 1104\t\t\n",
    "   1 NA:\tAldaco V1 1104\t\t\n",
    "   7 NA:\tBlanca 2012\t\t\n",
    "  18 NA:\tBlanca 2012\tBlanca M4 2102\t\n",
    "  21 NA:\tBlanca 2102 M3\t\t\n",
    "   5 NA:\tBlanca 2102 M5\t\t\n",
    "  28 NA:\tBlanca 2102 M5\tBlanca M5 2102\t\n",
    "   7 NA:\tBlanca 2104 M6\t\t\n",
    "  17 NA:\tBlanca 2104 M6\tBlanca M6 2104\t\n",
    "  23 NA:\tBlanca 9104\t\t\n",
    "   1 NA:\tBlanca M2 9104\t\t\n",
    "   1 NA:\tBlanca M2 9104\tBlanca M2\t\n",
    "  14 NA:\tBlanca M2 9104\tBlanca M2\tBlanca M2\n",
    "   2 NA:\tBlanca M3 4105\t\t\n",
    "   1 NA:\tBlanca M3 4105\t\tBlanca M3\n",
    "   4 NA:\tBlanca M3 4105\tBlanca M3\t\n",
    "   9 NA:\tBlanca M3 4105\tBlanca M3\tBlanca M3\n",
    "   2 NA:\tBlanca M3 4105\tBlanca M4\tBlanca M4\n",
    "   2 NA:\tBlanca M4 2102\t\t\n",
    "   3 NA:\tBlanca M4 2102\tBlanca M4\t\n",
    "   7 NA:\tBlanca M4 2102\tBlanca M4\tBlanca M4\n",
    "   1 NA:\tBlanca M5 2102\t\t\n",
    "   1 NA:\tBlanca M5 2102\tBlanca M4\tBlanca M5\n",
    "   1 NA:\tBlanca M5 2102\tBlanca M5\t\n",
    "   2 NA:\tBlanca M5 2102\tBlanca M5\tBlanca M4\n",
    "  20 NA:\tBlanca M5 2102\tBlanca M5\tBlanca M5\n",
    "   1 NA:\tBlanca M6 2105\t\t\n",
    "   1 NA:\tBlanca M6 2105\t\tBlanca M6\n",
    "   5 NA:\tBlanca M6 2105\tBlanca M6\t\n",
    "  25 NA:\tBlanca M6 2105\tBlanca M6\tBlanca M6\n",
    "   1 NA:\tCelso\t\t\n",
    "   1 NA:\tSara\t\t\n",
    "   1 NA:\tSara\tSara\tSara Jueves\n",
    "   1 NA:\tSara\tSara\tSara Martes\n",
    "  20 NA:\tSara Jueves\t\t\n",
    "   1 NA:\tSara Jueves\t\tSara\n",
    "   7 NA:\tSara Jueves\t\tSara Jueves\n",
    "  10 NA:\tSara Jueves\t\tSara Martes\n",
    "   5 NA:\tSara Jueves\tSara Jueves\t\n",
    "   8 NA:\tSara Jueves\tSara Jueves\tSara Jueves\n",
    "  17 NA:\tSara Jueves\tSara Jueves\tSara Martes\n",
    "  12 NA:\tSara Martes\t\t\n",
    "  11 NA:\tSara Martes\t\tSara Martes\n",
    "   1 NA:\tSara Martes\tSara Jueves\tSara Martes\n",
    "   3 NA:\tSara Martes\tSara Martes\t\n",
    "   3 NA:\tSara Martes\tSara Martes\tSara\n",
    "   1 NA:\tSara Martes\tSara Martes\tSara Jueves\n",
    "  28 NA:\tSara Martes\tSara Martes\tSara Martes\n",
    "   9 elisa:\t\t\t\n",
    "   5 elisa:\t\t\tElisa V4\n",
    "   2 elisa:\t\tElisa M4\tElisa M4\n",
    "   1 elisa:\t\tElisa V1\t\n",
    "   2 elisa:\t\tElisa V1\tElisa V1\n",
    "   3 elisa:\t\tElisa V4\t\n",
    "   1 elisa:\t\tElisa V4\tElisa M4\n",
    "   1 elisa:\tElisa\tElisa M4\t\n",
    "  42 elisa:\tElisa M4\t\t\n",
    "   2 elisa:\tElisa M4\t\tElisa M4\n",
    "  33 elisa:\tElisa M4\tElisa M4\t\n",
    "  70 elisa:\tElisa M4\tElisa M4\tElisa M4\n",
    "   1 elisa:\tElisa M4\tElisa M4\tElisa V1\n",
    "   2 elisa:\tElisa M4\tElisa M4\tElisa V4\n",
    "   1 elisa:\tElisa M4\tElisa V4\t\n",
    "  39 elisa:\tElisa V1\t\t\n",
    "   1 elisa:\tElisa V1\t\tElisa M4\n",
    "   6 elisa:\tElisa V1\t\tElisa V1\n",
    "   1 elisa:\tElisa V1\t\tElisa V4\n",
    "   2 elisa:\tElisa V1\tElisa M4\tElisa M4\n",
    "   1 elisa:\tElisa V1\tElisa M4\tElisa V1\n",
    "  24 elisa:\tElisa V1\tElisa V1\t\n",
    "  64 elisa:\tElisa V1\tElisa V1\tElisa V1\n",
    "   1 elisa:\tElisa V1\tElisa V1\tElisa V4\n",
    "   1 elisa:\tElisa V1\tElisa V4\tElisa V1\n",
    "   2 elisa:\tElisa V1\tElisa V4\tElisa V4\n",
    "  47 elisa:\tElisa V4\t\t\n",
    "   5 elisa:\tElisa V4\t\tElisa V4\n",
    "   2 elisa:\tElisa V4\tElisa M4\tElisa V4\n",
    "  25 elisa:\tElisa V4\tElisa V4\t\n",
    "  70 elisa:\tElisa V4\tElisa V4\tElisa V4\n",
    "  54 moi:\t\t\t\n",
    "  13 moi:\t\t\tMoises\n",
    "   1 moi:\t\t\tMoises 1101\n",
    "   5 moi:\t\tMoisés\t\n",
    "   8 moi:\t\tMoisés\tMoises\n",
    "  19 moi:\tMoises 1101\t\t\n",
    "   3 moi:\tMoises 1101\t\tMoises\n",
    "   3 moi:\tMoises 1101\tMoisés\t\n",
    "   7 moi:\tMoises 1101\tMoisés\tMoises\n",
    "   1 profe:\tgrupo_x\tgrupo_y\tgrupo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, aquí ¿qué pasa? \n",
    "\n",
    "Los 54 de moi que no tienen grupo deben ser alumnos a los cuales Moisés capturó una calificación \n",
    "(están en el data frame cf) pero que no han contestado ninguna encuesta. \n",
    "\n",
    "Igual los 9 de elisa que no tienen grupo ninguno. Pinta que hicimos bien la asignación.\n",
    "\n",
    "Regresemos a la metas planteadas para la P2:\n",
    "\n",
    "1. combinar la información de los resultados de 1ra y 2da oportunidad con los datos de las encuestas\n",
    "\n",
    "Ya quedó.\n",
    "\n",
    "2. agregar una variable categórica para cada alumno, nombrando los casos de la siguiente forma\n",
    "    * 1ra: aprobó la unidad de aprendizaje en primera oportunidad\n",
    "    * 2da: aprobó la unidad de aprendizaje en segunda oportunidad\n",
    "    * 3ra: presentó y reprobó ambas la 1ra y la 2da oportunidad\n",
    "\n",
    "Esto lo podemos hacer ahora para alumnos de moi y elisa los dos. Regresemos a pandas brevemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv(\"datos.csv\")\n",
    "casos = []\n",
    "for i in d.index:\n",
    "    cf1ra = str(d['1ra'][i])\n",
    "    cf2da = str(d['2da'][i])\n",
    "    if cf1ra.isdigit() and int(cf1ra) >= 70:\n",
    "        casos.append('1ra')\n",
    "    elif cf2da.isdigit() and int(cf2da) >= 70:\n",
    "        casos.append('2da')\n",
    "    elif cf1ra.isdigit() and cf2da.isdigit():\n",
    "        casos.append('3ra')\n",
    "    else:\n",
    "        casos.append('NA') # con los datos actuales, no se sabe si tienen derecho                                               \n",
    "d['caso'] = casos\n",
    "d.to_csv('casos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk -F \",\" '{print $64}' < casos.csv | sort | uniq -c\n",
    " 276 1ra\n",
    "  52 2da\n",
    "  18 3ra\n",
    " 676 NA\n",
    "   1 caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora queda la bronca de distinguir entre estos dos escenarios:\n",
    "\n",
    "* 5ta: no participó lo suficiente para tener derecho a segunda oportunidad\n",
    "*  NA: no se cuenta con información sobre sí o no participó o tuvo derecho en 1ra y 2da oportunidad \n",
    "\n",
    "lo que sí viene en elisa.dat: si dice NC, no tenía derecho a segundas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grep NC elisa/elisa.dat | wc -l \n",
    "     118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. extraer datos de encuestas para un caso específico o para una combinación de casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv(\"casos.csv\")\n",
    "theGood = d.loc[d['caso'] == '1ra']\n",
    "theBad = d.loc[d['caso'] == '2da']\n",
    "theUgly = d.loc[d['caso'] == '3ra']\n",
    "theGood.to_csv(\"good.csv\")\n",
    "theBad.to_csv(\"bad.csv\")\n",
    "theUgly.to_csv(\"ugly.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. determinar cuántos estudiantes por semestre y por maestro hay en cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grep elisa good.csv | awk -F \",\" '{print $4}' | sort | uniq -c\n",
    "  59 ad17\n",
    "  60 ad18\n",
    "  18 ej17\n",
    "  66 ej18\n",
    "grep moi good.csv | awk -F \",\" '{print $4}' | sort | uniq -c\n",
    "  20 ad17\n",
    "  23 ej17\n",
    "  30 ej18\n",
    "grep elisa bad.csv | awk -F \",\" '{print $4}' | sort | uniq -c\n",
    "  12 ad17\n",
    "   5 ad18\n",
    "  17 ej17\n",
    "  10 ej18\n",
    "grep moi bad.csv | awk -F \",\" '{print $4}' | sort | uniq -c\n",
    "   8 ej17\n",
    "grep elisa ugly.csv | awk -F \",\" '{print $4}' | sort | uniq -c\n",
    "   2 ad17\n",
    "   3 ad18\n",
    "   5 ej17\n",
    "   8 ej18\n",
    "grep moi ugly.csv | awk -F \",\" '{print $4}' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues, ya fue un avance razonable para la segunda fase del proyecto. \n",
    "\n",
    "Con algo parecido con sus datos, ya liberan su reporte de la segunda práctica.\n",
    "\n",
    "Prueben por lo menos la funcionalidad básica de pandas para\n",
    "\n",
    "* leer data frames de archivos\n",
    "* escribir data frames en CSV\n",
    "* agregar columnas en data frames\n",
    "* combinar dos o más data frames\n",
    "* filtrar renglones de un data frame \n",
    "\n",
    "para convencerme que sí lo saben usar para eso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
